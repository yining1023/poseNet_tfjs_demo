{"dependencies":[{"name":"/Users/yiningshi/dev/tfjs-models/posenet/demos/package.json","includedInParent":true,"mtime":1530912130696},{"name":"/Users/yiningshi/dev/tfjs-models/posenet/demos/.babelrc","includedInParent":true,"mtime":1529855715672},{"name":"/Users/yiningshi/dev/tfjs-models/posenet/tsconfig.json","includedInParent":true,"mtime":1529855715734},{"name":"@tensorflow/tfjs","loc":{"line":39,"column":17}},{"name":"./checkpoint_loader","loc":{"line":40,"column":34}},{"name":"./checkpoints","loc":{"line":41,"column":28}},{"name":"./mobilenet","loc":{"line":42,"column":26}},{"name":"./multiPose/decodeMultiplePoses","loc":{"line":43,"column":36}},{"name":"./singlePose/decodeSinglePose","loc":{"line":44,"column":33}},{"name":"./util","loc":{"line":45,"column":21}}],"generated":{"js":"\"use strict\";\nvar __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {\n    return new (P || (P = Promise))(function (resolve, reject) {\n        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }\n        function rejected(value) { try { step(generator[\"throw\"](value)); } catch (e) { reject(e); } }\n        function step(result) { result.done ? resolve(result.value) : new P(function (resolve) { resolve(result.value); }).then(fulfilled, rejected); }\n        step((generator = generator.apply(thisArg, _arguments || [])).next());\n    });\n};\nvar __generator = (this && this.__generator) || function (thisArg, body) {\n    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;\n    return g = { next: verb(0), \"throw\": verb(1), \"return\": verb(2) }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function() { return this; }), g;\n    function verb(n) { return function (v) { return step([n, v]); }; }\n    function step(op) {\n        if (f) throw new TypeError(\"Generator is already executing.\");\n        while (_) try {\n            if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n            if (y = 0, t) op = [op[0] & 2, t.value];\n            switch (op[0]) {\n                case 0: case 1: t = op; break;\n                case 4: _.label++; return { value: op[1], done: false };\n                case 5: _.label++; y = op[1]; op = [0]; continue;\n                case 7: op = _.ops.pop(); _.trys.pop(); continue;\n                default:\n                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }\n                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }\n                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }\n                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }\n                    if (t[2]) _.ops.pop();\n                    _.trys.pop(); continue;\n            }\n            op = body.call(thisArg, _);\n        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }\n        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };\n    }\n};\nvar _this = this;\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar tf = require(\"@tensorflow/tfjs\");\nvar checkpoint_loader_1 = require(\"./checkpoint_loader\");\nvar checkpoints_1 = require(\"./checkpoints\");\nvar mobilenet_1 = require(\"./mobilenet\");\nvar decodeMultiplePoses_1 = require(\"./multiPose/decodeMultiplePoses\");\nvar decodeSinglePose_1 = require(\"./singlePose/decodeSinglePose\");\nvar util_1 = require(\"./util\");\nfunction toInputTensor(input, resizeHeight, resizeWidth, flipHorizontal) {\n    var imageTensor = input instanceof tf.Tensor ? input : tf.fromPixels(input);\n    if (flipHorizontal) {\n        return imageTensor.reverse(1).resizeBilinear([resizeHeight, resizeWidth]);\n    }\n    else {\n        return imageTensor.resizeBilinear([resizeHeight, resizeWidth]);\n    }\n}\nvar PoseNet = (function () {\n    function PoseNet(mobileNet) {\n        this.mobileNet = mobileNet;\n    }\n    PoseNet.prototype.predictForSinglePose = function (input, outputStride) {\n        var _this = this;\n        if (outputStride === void 0) { outputStride = 16; }\n        mobilenet_1.assertValidOutputStride(outputStride);\n        return tf.tidy(function () {\n            var mobileNetOutput = _this.mobileNet.predict(input, outputStride);\n            var heatmaps = _this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n            var offsets = _this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n            console.log('heatmaps: ', heatmaps);\n            console.log('offsets: ', offsets);\n            return { heatmapScores: heatmaps.sigmoid(), offsets: offsets };\n        });\n    };\n    PoseNet.prototype.predictForMultiPose = function (input, outputStride) {\n        var _this = this;\n        if (outputStride === void 0) { outputStride = 16; }\n        return tf.tidy(function () {\n            var mobileNetOutput = _this.mobileNet.predict(input, outputStride);\n            var heatmaps = _this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n            var offsets = _this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n            var displacementFwd = _this.mobileNet.convToOutput(mobileNetOutput, 'displacement_fwd_2');\n            var displacementBwd = _this.mobileNet.convToOutput(mobileNetOutput, 'displacement_bwd_2');\n            return {\n                heatmapScores: heatmaps.sigmoid(),\n                offsets: offsets,\n                displacementFwd: displacementFwd,\n                displacementBwd: displacementBwd\n            };\n        });\n    };\n    PoseNet.prototype.estimateSinglePose = function (input, imageScaleFactor, flipHorizontal, outputStride) {\n        if (imageScaleFactor === void 0) { imageScaleFactor = 0.5; }\n        if (flipHorizontal === void 0) { flipHorizontal = false; }\n        if (outputStride === void 0) { outputStride = 16; }\n        return __awaiter(this, void 0, Promise, function () {\n            var _a, height, width, resizedHeight, resizedWidth, _b, heatmapScores, offsets, pose, scaleY, scaleX;\n            var _this = this;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        mobilenet_1.assertValidOutputStride(outputStride);\n                        mobilenet_1.assertValidScaleFactor(imageScaleFactor);\n                        _a = input instanceof tf.Tensor ?\n                            [input.shape[0], input.shape[1]] :\n                            [input.height, input.width], height = _a[0], width = _a[1];\n                        resizedHeight = util_1.getValidResolution(imageScaleFactor, height, outputStride);\n                        resizedWidth = util_1.getValidResolution(imageScaleFactor, width, outputStride);\n                        _b = tf.tidy(function () {\n                            var inputTensor = toInputTensor(input, resizedHeight, resizedWidth, flipHorizontal);\n                            console.log('inputTensor: ', inputTensor);\n                            console.log('outputStride: ', outputStride);\n                            return _this.predictForSinglePose(inputTensor, outputStride);\n                        }), heatmapScores = _b.heatmapScores, offsets = _b.offsets;\n                        console.log('heatmapScores: ', heatmapScores);\n                        console.log('offsets: ', offsets);\n                        console.log('data', offsets.dataSync());\n                        return [4, decodeSinglePose_1.decodeSinglePose(heatmapScores, offsets, outputStride)];\n                    case 1:\n                        pose = _c.sent();\n                        console.log('pose: ', pose);\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        scaleY = height / resizedHeight;\n                        scaleX = width / resizedWidth;\n                        return [2, util_1.scalePose(pose, scaleY, scaleX)];\n                }\n            });\n        });\n    };\n    PoseNet.prototype.estimateMultiplePoses = function (input, imageScaleFactor, flipHorizontal, outputStride, maxDetections, scoreThreshold, nmsRadius) {\n        if (imageScaleFactor === void 0) { imageScaleFactor = 0.5; }\n        if (flipHorizontal === void 0) { flipHorizontal = false; }\n        if (outputStride === void 0) { outputStride = 16; }\n        if (maxDetections === void 0) { maxDetections = 5; }\n        if (scoreThreshold === void 0) { scoreThreshold = .5; }\n        if (nmsRadius === void 0) { nmsRadius = 20; }\n        return __awaiter(this, void 0, Promise, function () {\n            var _a, height, width, resizedHeight, resizedWidth, _b, heatmapScores, offsets, displacementFwd, displacementBwd, poses, scaleY, scaleX;\n            var _this = this;\n            return __generator(this, function (_c) {\n                switch (_c.label) {\n                    case 0:\n                        mobilenet_1.assertValidOutputStride(outputStride);\n                        mobilenet_1.assertValidScaleFactor(imageScaleFactor);\n                        _a = input instanceof tf.Tensor ?\n                            [input.shape[0], input.shape[1]] :\n                            [input.height, input.width], height = _a[0], width = _a[1];\n                        resizedHeight = util_1.getValidResolution(imageScaleFactor, height, outputStride);\n                        resizedWidth = util_1.getValidResolution(imageScaleFactor, width, outputStride);\n                        _b = tf.tidy(function () {\n                            var inputTensor = toInputTensor(input, resizedHeight, resizedWidth, flipHorizontal);\n                            return _this.predictForMultiPose(inputTensor, outputStride);\n                        }), heatmapScores = _b.heatmapScores, offsets = _b.offsets, displacementFwd = _b.displacementFwd, displacementBwd = _b.displacementBwd;\n                        return [4, decodeMultiplePoses_1.decodeMultiplePoses(heatmapScores, offsets, displacementFwd, displacementBwd, outputStride, maxDetections, scoreThreshold, nmsRadius)];\n                    case 1:\n                        poses = _c.sent();\n                        heatmapScores.dispose();\n                        offsets.dispose();\n                        displacementFwd.dispose();\n                        displacementBwd.dispose();\n                        scaleY = height / resizedHeight;\n                        scaleX = width / resizedWidth;\n                        return [2, util_1.scalePoses(poses, scaleY, scaleX)];\n                }\n            });\n        });\n    };\n    PoseNet.prototype.dispose = function () {\n        this.mobileNet.dispose();\n    };\n    return PoseNet;\n}());\nexports.PoseNet = PoseNet;\nfunction load(multiplier) {\n    if (multiplier === void 0) { multiplier = 1.01; }\n    return __awaiter(this, void 0, Promise, function () {\n        var possibleMultipliers, mobileNet;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    if (tf == null) {\n                        throw new Error(\"Cannot find TensorFlow.js. If you are using a <script> tag, please \" +\n                            \"also include @tensorflow/tfjs on the page before using this model.\");\n                    }\n                    possibleMultipliers = Object.keys(checkpoints_1.checkpoints);\n                    tf.util.assert(typeof multiplier === 'number', \"got multiplier type of \" + typeof multiplier + \" when it should be a \" +\n                        \"number.\");\n                    tf.util.assert(possibleMultipliers.indexOf(multiplier.toString()) >= 0, \"invalid multiplier value of \" + multiplier + \".  No checkpoint exists for that \" +\n                        (\"multiplier. Must be one of \" + possibleMultipliers.join(',') + \".\"));\n                    return [4, exports.mobilenetLoader.load(multiplier)];\n                case 1:\n                    mobileNet = _a.sent();\n                    return [2, new PoseNet(mobileNet)];\n            }\n        });\n    });\n}\nexports.load = load;\nexports.mobilenetLoader = {\n    load: function (multiplier) { return __awaiter(_this, void 0, Promise, function () {\n        var checkpoint, checkpointLoader, variables;\n        return __generator(this, function (_a) {\n            switch (_a.label) {\n                case 0:\n                    checkpoint = checkpoints_1.checkpoints[multiplier];\n                    checkpointLoader = new checkpoint_loader_1.CheckpointLoader(checkpoint.url);\n                    return [4, checkpointLoader.getAllVariables()];\n                case 1:\n                    variables = _a.sent();\n                    return [2, new mobilenet_1.MobileNet(variables, checkpoint.architecture)];\n            }\n        });\n    }); }\n};\n","map":{"version":3,"file":"posenet_model.js","sourceRoot":"","sources":["../src/posenet_model.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAiBA,iBAsSA;;AAtSA,qCAAuC;AAEvC,yDAAqD;AACrD,6CAA0C;AAE1C,yCAA0H;AAC1H,uEAAoE;AACpE,kEAA+D;AAE/D,+BAAiE;AAOjE,uBACI,KAAgB,EAAE,YAAoB,EAAE,WAAmB,EAC3D,cAAuB;IACzB,IAAM,WAAW,GAAG,KAAK,YAAY,EAAE,CAAC,MAAM,CAAC,CAAC,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,CAAC,UAAU,CAAC,KAAK,CAAC,CAAC;IAE9E,IAAI,cAAc,EAAE;QAClB,OAAO,WAAW,CAAC,OAAO,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;KAC3E;SAAM;QACL,OAAO,WAAW,CAAC,cAAc,CAAC,CAAC,YAAY,EAAE,WAAW,CAAC,CAAC,CAAC;KAChE;AACH,CAAC;AAED;IAGE,iBAAY,SAAoB;QAC9B,IAAI,CAAC,SAAS,GAAG,SAAS,CAAC;IAC7B,CAAC;IAcD,sCAAoB,GAApB,UAAqB,KAAkB,EAAE,YAA+B;QAAxE,iBAcC;QAdwC,6BAAA,EAAA,iBAA+B;QAEtE,mCAAuB,CAAC,YAAY,CAAC,CAAC;QACtC,OAAO,EAAE,CAAC,IAAI,CAAC;YACb,IAAM,eAAe,GAAG,KAAI,CAAC,SAAS,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;YAEpE,IAAM,QAAQ,GACV,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,WAAW,CAAC,CAAC;YAE9D,IAAM,OAAO,GAAG,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,UAAU,CAAC,CAAC;YACzE,OAAO,CAAC,GAAG,CAAC,YAAY,EAAE,QAAQ,CAAC,CAAC;YACpC,OAAO,CAAC,GAAG,CAAC,WAAW,EAAE,OAAO,CAAC,CAAC;YAClC,OAAO,EAAC,aAAa,EAAE,QAAQ,CAAC,OAAO,EAAE,EAAE,OAAO,SAAA,EAAC,CAAC;QACtD,CAAC,CAAC,CAAC;IACL,CAAC;IAeD,qCAAmB,GAAnB,UAAoB,KAAkB,EAAE,YAA+B;QAAvE,iBA2BC;QA3BuC,6BAAA,EAAA,iBAA+B;QAMrE,OAAO,EAAE,CAAC,IAAI,CAAC;YACb,IAAM,eAAe,GAAG,KAAI,CAAC,SAAS,CAAC,OAAO,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC;YAEpE,IAAM,QAAQ,GACV,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,WAAW,CAAC,CAAC;YAE9D,IAAM,OAAO,GAAG,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,UAAU,CAAC,CAAC;YAEzE,IAAM,eAAe,GACjB,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,oBAAoB,CAAC,CAAC;YAEvE,IAAM,eAAe,GACjB,KAAI,CAAC,SAAS,CAAC,YAAY,CAAC,eAAe,EAAE,oBAAoB,CAAC,CAAC;YAEvE,OAAO;gBACL,aAAa,EAAE,QAAQ,CAAC,OAAO,EAAE;gBACjC,OAAO,SAAA;gBACP,eAAe,iBAAA;gBACf,eAAe,iBAAA;aAChB,CAAC;QACJ,CAAC,CAAC,CAAC;IACL,CAAC;IA4BK,oCAAkB,GAAxB,UACI,KAAgB,EAAE,gBAAsB,EAAE,cAAsB,EAChE,YAA+B;QADb,iCAAA,EAAA,sBAAsB;QAAE,+BAAA,EAAA,sBAAsB;QAChE,6BAAA,EAAA,iBAA+B;uCAAG,OAAO;;;;;;wBAC3C,mCAAuB,CAAC,YAAY,CAAC,CAAC;wBACtC,kCAAsB,CAAC,gBAAgB,CAAC,CAAC;wBAEnC,KAAkB,KAAK,YAAY,EAAE,CAAC,MAAM,CAAC,CAAC;4BAChD,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;4BAClC,CAAC,KAAK,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,CAAC,EAFxB,MAAM,QAAA,EAAE,KAAK,QAAA,CAEY;wBAC1B,aAAa,GACf,yBAAkB,CAAC,gBAAgB,EAAE,MAAM,EAAE,YAAY,CAAC,CAAC;wBACzD,YAAY,GACd,yBAAkB,CAAC,gBAAgB,EAAE,KAAK,EAAE,YAAY,CAAC,CAAC;wBAExD,KAA2B,EAAE,CAAC,IAAI,CAAC;4BACvC,IAAM,WAAW,GACb,aAAa,CAAC,KAAK,EAAE,aAAa,EAAE,YAAY,EAAE,cAAc,CAAC,CAAC;4BACtE,OAAO,CAAC,GAAG,CAAC,eAAe,EAAE,WAAW,CAAC,CAAC;4BAC1C,OAAO,CAAC,GAAG,CAAC,gBAAgB,EAAE,YAAY,CAAC,CAAC;4BAC5C,OAAO,KAAI,CAAC,oBAAoB,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;wBAC9D,CAAC,CAAC,EANK,aAAa,mBAAA,EAAE,OAAO,aAAA,CAM1B;wBACH,OAAO,CAAC,GAAG,CAAC,iBAAiB,EAAE,aAAa,CAAC,CAAC;wBAC9C,OAAO,CAAC,GAAG,CAAC,WAAW,EAAE,OAAO,CAAC,CAAC;wBAClC,OAAO,CAAC,GAAG,CAAC,MAAM,EAAE,OAAO,CAAC,QAAQ,EAAE,CAAC,CAAC;wBAC3B,WAAM,mCAAgB,CAAC,aAAa,EAAE,OAAO,EAAE,YAAY,CAAC,EAAA;;wBAAnE,IAAI,GAAG,SAA4D;wBACzE,OAAO,CAAC,GAAG,CAAC,QAAQ,EAAE,IAAI,CAAC,CAAC;wBAC5B,aAAa,CAAC,OAAO,EAAE,CAAC;wBACxB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAEZ,MAAM,GAAG,MAAM,GAAG,aAAa,CAAC;wBAChC,MAAM,GAAG,KAAK,GAAG,YAAY,CAAC;wBAEpC,WAAO,gBAAS,CAAC,IAAI,EAAE,MAAM,EAAE,MAAM,CAAC,EAAC;;;;KACxC;IAyCK,uCAAqB,GAA3B,UACI,KAAgB,EAAE,gBAAsB,EAAE,cAAsB,EAChE,YAA+B,EAAE,aAAiB,EAAE,cAAmB,EACvE,SAAc;QAFI,iCAAA,EAAA,sBAAsB;QAAE,+BAAA,EAAA,sBAAsB;QAChE,6BAAA,EAAA,iBAA+B;QAAE,8BAAA,EAAA,iBAAiB;QAAE,+BAAA,EAAA,mBAAmB;QACvE,0BAAA,EAAA,cAAc;uCAAG,OAAO;;;;;;wBAC1B,mCAAuB,CAAC,YAAY,CAAC,CAAC;wBACtC,kCAAsB,CAAC,gBAAgB,CAAC,CAAC;wBAEnC,KAAkB,KAAK,YAAY,EAAE,CAAC,MAAM,CAAC,CAAC;4BAChD,CAAC,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,EAAE,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC,CAAC,CAAC;4BAClC,CAAC,KAAK,CAAC,MAAM,EAAE,KAAK,CAAC,KAAK,CAAC,EAFxB,MAAM,QAAA,EAAE,KAAK,QAAA,CAEY;wBAC1B,aAAa,GACf,yBAAkB,CAAC,gBAAgB,EAAE,MAAM,EAAE,YAAY,CAAC,CAAC;wBACzD,YAAY,GACd,yBAAkB,CAAC,gBAAgB,EAAE,KAAK,EAAE,YAAY,CAAC,CAAC;wBAExD,KACF,EAAE,CAAC,IAAI,CAAC;4BACN,IAAM,WAAW,GACb,aAAa,CAAC,KAAK,EAAE,aAAa,EAAE,YAAY,EAAE,cAAc,CAAC,CAAC;4BACtE,OAAO,KAAI,CAAC,mBAAmB,CAAC,WAAW,EAAE,YAAY,CAAC,CAAC;wBAC7D,CAAC,CAAC,EALC,aAAa,mBAAA,EAAE,OAAO,aAAA,EAAE,eAAe,qBAAA,EAAE,eAAe,qBAAA,CAKxD;wBAEO,WAAM,yCAAmB,CACnC,aAAa,EAAE,OAAO,EAAE,eAAe,EAAE,eAAe,EAAE,YAAY,EACtE,aAAa,EAAE,cAAc,EAAE,SAAS,CAAC,EAAA;;wBAFvC,KAAK,GAAG,SAE+B;wBAE7C,aAAa,CAAC,OAAO,EAAE,CAAC;wBACxB,OAAO,CAAC,OAAO,EAAE,CAAC;wBAClB,eAAe,CAAC,OAAO,EAAE,CAAC;wBAC1B,eAAe,CAAC,OAAO,EAAE,CAAC;wBAEpB,MAAM,GAAG,MAAM,GAAG,aAAa,CAAC;wBAChC,MAAM,GAAG,KAAK,GAAG,YAAY,CAAC;wBAEpC,WAAO,iBAAU,CAAC,KAAK,EAAE,MAAM,EAAE,MAAM,CAAC,EAAC;;;;KAC1C;IAEM,yBAAO,GAAd;QACE,IAAI,CAAC,SAAS,CAAC,OAAO,EAAE,CAAC;IAC3B,CAAC;IACH,cAAC;AAAD,CAAC,AAzND,IAyNC;AAzNY,0BAAO;AAuOpB,cAA2B,UAAsC;IAAtC,2BAAA,EAAA,iBAAsC;mCAC7D,OAAO;;;;;oBACT,IAAI,EAAE,IAAI,IAAI,EAAE;wBACd,MAAM,IAAI,KAAK,CACX,qEAAqE;4BACrE,oEAAoE,CAAC,CAAC;qBAC3E;oBACK,mBAAmB,GAAG,MAAM,CAAC,IAAI,CAAC,yBAAW,CAAC,CAAC;oBACrD,EAAE,CAAC,IAAI,CAAC,MAAM,CACV,OAAO,UAAU,KAAK,QAAQ,EAC9B,4BAA0B,OAAO,UAAU,0BAAuB;wBAC9D,SAAS,CAAC,CAAC;oBAEnB,EAAE,CAAC,IAAI,CAAC,MAAM,CACV,mBAAmB,CAAC,OAAO,CAAC,UAAU,CAAC,QAAQ,EAAE,CAAC,IAAI,CAAC,EACvD,iCACI,UAAU,sCAAmC;yBAC7C,gCAA8B,mBAAmB,CAAC,IAAI,CAAC,GAAG,CAAC,MAAG,CAAA,CAAC,CAAC;oBAEtD,WAAM,uBAAe,CAAC,IAAI,CAAC,UAAU,CAAC,EAAA;;oBAAlD,SAAS,GAAG,SAAsC;oBAExD,WAAO,IAAI,OAAO,CAAC,SAAS,CAAC,EAAC;;;;CAC/B;AAtBD,oBAsBC;AAEY,QAAA,eAAe,GAAG;IAC7B,IAAI,EAAE,UAAM,UAA+B,oCAAG,OAAO;;;;;oBAC7C,UAAU,GAAG,yBAAW,CAAC,UAAU,CAAC,CAAC;oBAErC,gBAAgB,GAAG,IAAI,oCAAgB,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC;oBAE5C,WAAM,gBAAgB,CAAC,eAAe,EAAE,EAAA;;oBAApD,SAAS,GAAG,SAAwC;oBAE1D,WAAO,IAAI,qBAAS,CAAC,SAAS,EAAE,UAAU,CAAC,YAAY,CAAC,EAAC;;;SAC1D;CACF,CAAC","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs';\n\nimport {CheckpointLoader} from './checkpoint_loader';\nimport {checkpoints} from './checkpoints';\n// tslint:disable-next-line:max-line-length\nimport {assertValidOutputStride, assertValidScaleFactor, MobileNet, MobileNetMultiplier, OutputStride} from './mobilenet';\nimport {decodeMultiplePoses} from './multiPose/decodeMultiplePoses';\nimport {decodeSinglePose} from './singlePose/decodeSinglePose';\nimport {Pose} from './types';\nimport {getValidResolution, scalePose, scalePoses} from './util';\n\nexport type PoseNetResolution = 161|193|257|289|321|353|385|417|449|481|513;\n\nexport type InputType =\n    ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement|tf.Tensor3D;\n\nfunction toInputTensor(\n    input: InputType, resizeHeight: number, resizeWidth: number,\n    flipHorizontal: boolean): tf.Tensor3D {\n  const imageTensor = input instanceof tf.Tensor ? input : tf.fromPixels(input);\n\n  if (flipHorizontal) {\n    return imageTensor.reverse(1).resizeBilinear([resizeHeight, resizeWidth]);\n  } else {\n    return imageTensor.resizeBilinear([resizeHeight, resizeWidth]);\n  }\n}\n\nexport class PoseNet {\n  mobileNet: MobileNet;\n\n  constructor(mobileNet: MobileNet) {\n    this.mobileNet = mobileNet;\n  }\n\n  /**\n   * Infer through PoseNet. This does standard ImageNet pre-processing before\n   * inferring through the model. The image should pixels should have values\n   * [0-255]. This method returns the heatmaps and offsets.  Infers through the\n   * outputs that are needed for single pose decoding\n   *\n   * @param input un-preprocessed input image, with values in range [0-255]\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16.  The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return heatmapScores, offsets\n   */\n  predictForSinglePose(input: tf.Tensor3D, outputStride: OutputStride = 16):\n      {heatmapScores: tf.Tensor3D, offsets: tf.Tensor3D} {\n    assertValidOutputStride(outputStride);\n    return tf.tidy(() => {\n      const mobileNetOutput = this.mobileNet.predict(input, outputStride);\n\n      const heatmaps =\n          this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n\n      const offsets = this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n      console.log('heatmaps: ', heatmaps);\n      console.log('offsets: ', offsets);\n      return {heatmapScores: heatmaps.sigmoid(), offsets};\n    });\n  }\n\n  /**\n   * Infer through PoseNet. This does standard ImageNet pre-processing before\n   * inferring through the model. The image should pixels should have values\n   * [0-255]. Infers through the outputs that are needed for multiple pose\n   * decoding. This method returns the heatmaps offsets, and mid-range\n   * displacements.\n   *\n   * @param input un-preprocessed input image, with values in range [0-255]\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return heatmapScores, offsets, displacementFwd, displacementBwd\n   */\n  predictForMultiPose(input: tf.Tensor3D, outputStride: OutputStride = 16): {\n    heatmapScores: tf.Tensor3D,\n    offsets: tf.Tensor3D,\n    displacementFwd: tf.Tensor3D,\n    displacementBwd: tf.Tensor3D\n  } {\n    return tf.tidy(() => {\n      const mobileNetOutput = this.mobileNet.predict(input, outputStride);\n\n      const heatmaps =\n          this.mobileNet.convToOutput(mobileNetOutput, 'heatmap_2');\n\n      const offsets = this.mobileNet.convToOutput(mobileNetOutput, 'offset_2');\n\n      const displacementFwd =\n          this.mobileNet.convToOutput(mobileNetOutput, 'displacement_fwd_2');\n\n      const displacementBwd =\n          this.mobileNet.convToOutput(mobileNetOutput, 'displacement_bwd_2');\n\n      return {\n        heatmapScores: heatmaps.sigmoid(),\n        offsets,\n        displacementFwd,\n        displacementBwd\n      };\n    });\n  }\n\n  /**\n   * Infer through PoseNet, and estimates a single pose using the outputs. This\n   * does standard ImageNet pre-processing before inferring through the model.\n   * The image should pixels should have values [0-255].\n   * This method returns a single pose.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param imageScaleFactor A number between 0.2 and 1. Defaults to 0.50. What\n   * to scale the image by before feeding it through the network.  Set this\n   * number lower to scale down the image and increase the speed when feeding\n   * through the network at the cost of accuracy.\n   *\n   * @param flipHorizontal.  Defaults to false.  If the poses should be\n   * flipped/mirrored  horizontally.  This should be set to true for videos\n   * where the video is by default flipped horizontally (i.e. a webcam), and you\n   * want the poses to be returned in the proper orientation.\n   *\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputDimension - 1)/outputStride + 1\n   * @return A single pose with a confidence score, which contains an array of\n   * keypoints indexed by part id, each with a score and position.  The\n   * positions of the keypoints are in the same scale as the original image\n   */\n  async estimateSinglePose(\n      input: InputType, imageScaleFactor = 0.5, flipHorizontal = false,\n      outputStride: OutputStride = 16): Promise<Pose> {\n    assertValidOutputStride(outputStride);\n    assertValidScaleFactor(imageScaleFactor);\n\n    const [height, width] = input instanceof tf.Tensor ?\n        [input.shape[0], input.shape[1]] :\n        [input.height, input.width];\n    const resizedHeight =\n        getValidResolution(imageScaleFactor, height, outputStride);\n    const resizedWidth =\n        getValidResolution(imageScaleFactor, width, outputStride);\n\n    const {heatmapScores, offsets} = tf.tidy(() => {\n      const inputTensor =\n          toInputTensor(input, resizedHeight, resizedWidth, flipHorizontal);\n      console.log('inputTensor: ', inputTensor);\n      console.log('outputStride: ', outputStride);\n      return this.predictForSinglePose(inputTensor, outputStride);\n    });\n    console.log('heatmapScores: ', heatmapScores);\n    console.log('offsets: ', offsets);\n    console.log('data', offsets.dataSync());\n    const pose = await decodeSinglePose(heatmapScores, offsets, outputStride);\n    console.log('pose: ', pose);\n    heatmapScores.dispose();\n    offsets.dispose();\n\n    const scaleY = height / resizedHeight;\n    const scaleX = width / resizedWidth;\n\n    return scalePose(pose, scaleY, scaleX);\n  }\n\n  /**\n   * Infer through PoseNet, and estimates multiple poses using the outputs.\n   * This does standard ImageNet pre-processing before inferring through the\n   * model. The image should pixels should have values [0-255]. It detects\n   * multiple poses and finds their parts from part scores and displacement\n   * vectors using a fast greedy decoding algorithm.  It returns up to\n   * `maxDetections` object instance detections in decreasing root score order.\n   *\n   * @param input ImageData|HTMLImageElement|HTMLCanvasElement|HTMLVideoElement)\n   * The input image to feed through the network.\n   *\n   * @param imageScaleFactor  A number between 0.2 and 1. Defaults to 0.50. What\n   * to scale the image by before feeding it through the network.  Set this\n   * number lower to scale down the image and increase the speed when feeding\n   * through the network at the cost of accuracy.\n   *\n   * @param flipHorizontal Defaults to false.  If the poses should be\n   * flipped/mirrored  horizontally.  This should be set to true for videos\n   * where the video is by default flipped horizontally (i.e. a webcam), and you\n   * want the poses to be returned in the proper orientation.\n   *\n   * @param outputStride the desired stride for the outputs.  Must be 32, 16,\n   * or 8. Defaults to 16. The output width and height will be will be\n   * (inputSize - 1)/outputStride + 1\n   *\n   * @param maxDetections Maximum number of returned instance detections per\n   * image. Defaults to 5.\n   *\n   * @param scoreThreshold Only return instance detections that have root part\n   * score greater or equal to this value. Defaults to 0.5\n   *\n   * @param nmsRadius Non-maximum suppression part distance in pixels. It needs\n   * to be strictly positive. Two parts suppress each other if they are less\n   * than `nmsRadius` pixels away. Defaults to 20.\n   *\n   * @return An array of poses and their scores, each containing keypoints and\n   * the corresponding keypoint scores.  The positions of the keypoints are\n   * in the same scale as the original image\n   */\n  async estimateMultiplePoses(\n      input: InputType, imageScaleFactor = 0.5, flipHorizontal = false,\n      outputStride: OutputStride = 16, maxDetections = 5, scoreThreshold = .5,\n      nmsRadius = 20): Promise<Pose[]> {\n    assertValidOutputStride(outputStride);\n    assertValidScaleFactor(imageScaleFactor);\n\n    const [height, width] = input instanceof tf.Tensor ?\n        [input.shape[0], input.shape[1]] :\n        [input.height, input.width];\n    const resizedHeight =\n        getValidResolution(imageScaleFactor, height, outputStride);\n    const resizedWidth =\n        getValidResolution(imageScaleFactor, width, outputStride);\n\n    const {heatmapScores, offsets, displacementFwd, displacementBwd} =\n        tf.tidy(() => {\n          const inputTensor =\n              toInputTensor(input, resizedHeight, resizedWidth, flipHorizontal);\n          return this.predictForMultiPose(inputTensor, outputStride);\n        });\n\n    const poses = await decodeMultiplePoses(\n        heatmapScores, offsets, displacementFwd, displacementBwd, outputStride,\n        maxDetections, scoreThreshold, nmsRadius);\n\n    heatmapScores.dispose();\n    offsets.dispose();\n    displacementFwd.dispose();\n    displacementBwd.dispose();\n\n    const scaleY = height / resizedHeight;\n    const scaleX = width / resizedWidth;\n\n    return scalePoses(poses, scaleY, scaleX);\n  }\n\n  public dispose() {\n    this.mobileNet.dispose();\n  }\n}\n\n/**\n * Loads the PoseNet model instance from a checkpoint, with the MobileNet\n * architecture specified by the multiplier.\n *\n * @param multiplier An optional number with values: 1.01, 1.0, 0.75, or\n * 0.50. Defaults to 1.01. It is the float multiplier for the depth (number of\n * channels) for all convolution ops. The value corresponds to a MobileNet\n * architecture and checkpoint.  The larger the value, the larger the size of\n * the layers, and more accurate the model at the cost of speed.  Set this to a\n * smaller value to increase speed at the cost of accuracy.\n *\n */\nexport async function load(multiplier: MobileNetMultiplier = 1.01):\n    Promise<PoseNet> {\n  if (tf == null) {\n    throw new Error(\n        `Cannot find TensorFlow.js. If you are using a <script> tag, please ` +\n        `also include @tensorflow/tfjs on the page before using this model.`);\n  }\n  const possibleMultipliers = Object.keys(checkpoints);\n  tf.util.assert(\n      typeof multiplier === 'number',\n      `got multiplier type of ${typeof multiplier} when it should be a ` +\n          `number.`);\n\n  tf.util.assert(\n      possibleMultipliers.indexOf(multiplier.toString()) >= 0,\n      `invalid multiplier value of ${\n          multiplier}.  No checkpoint exists for that ` +\n          `multiplier. Must be one of ${possibleMultipliers.join(',')}.`);\n\n  const mobileNet = await mobilenetLoader.load(multiplier);\n\n  return new PoseNet(mobileNet);\n}\n\nexport const mobilenetLoader = {\n  load: async(multiplier: MobileNetMultiplier): Promise<MobileNet> => {\n    const checkpoint = checkpoints[multiplier];\n\n    const checkpointLoader = new CheckpointLoader(checkpoint.url);\n\n    const variables = await checkpointLoader.getAllVariables();\n\n    return new MobileNet(variables, checkpoint.architecture);\n  }\n};\n"]}},"hash":"9c6eae80789ef919a1b46b8c699f3cf0","cacheData":{"env":{}}}